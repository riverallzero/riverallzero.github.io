---
layout: single
title: "OCR(TesseractOCR, EasyOCR, AzureAPI)"
categories: python
tag: [ocr, azure]
toc: true
toc_sticky: true
author_profile: true
search: true
---

# OCR이란?
광학 문자 인식(Optimal Character Recognition)은 텍스트 이미지를 기계가 읽을 수 있는 텍스트 포맷으로 변환하는 과정입니다. 예를 들어 양식 또는 영수증을 스캔하는 경우 컴퓨터는 스캔본을 이미지 파일로 저장합니다. 이미지 파일에서는 텍스트 편집기를 사용하여 단어를 편집, 검색하거나 단어 수를 계산할 수 없습니다. 그러나 OCR을 사용하면 이미지를 텍스트 문서로 변환하여 내용을 텍스트 데이터로 저장할 수 있습니다.

## 작동방식
-  이미지 획득 : 스캐너를 통해 문서를 읽어들여 이진 데이터로 변환합니다. OCR 소프트웨어는 스캔된 이미지를 분석하고 밝은 부분을 배경으로, 어두운 부분을 텍스트로 분류합니다.
-  전처리 : OCR 소프트웨어는 먼저 이미지를 정리하고 오류를 제거하여 읽을 수 있도록 준비합니다. 정리 기술은 다음과 같습니다.
스캔된 문서를 조금씩 기울기 보정하거나 틸팅하여 스캔 중의 정렬 문제를 해결합니다.
디지털 이미지의 얼룩을 제거하거나 텍스트 이미지의 가장자리를 부드럽게 만듭니다.
이미지 내의 텍스트 상자 및 선을 정리합니다.
- 텍스트 인식 : OCR 소프트웨어가 텍스트 인식에 사용하는 OCR 알고리즘 또는 소프트웨어 프로세스의 두 가지 주요 유형은 패턴 매칭 및 특징 추출이라고 합니다.
- 패턴 매칭 : 글리프라고 하는 문자 이미지를 격리해서 유사하게 저장된 글리프와 비교하여 작동합니다. 패턴 인식은 저장된 글리프가 입력된 글리프와 비슷한 폰트 및 크기를 가진 경우에만 작동합니다. 이 방법은 잘 알려진 폰트로 입력된 문서의 스캔 이미지에서 잘 작동합니다.
- 특징 추출 : 글리프를 선, 닫힌 고리, 선 방향 및 선 교차와 같은 특징으로 나누거나 분해합니다. 그런 다음 이런 특징을 사용하여 다양하게 저장된 글리프 가운데 가장 정확히 일치하거나 근사치에 가까운 글리프를 찾아냅니다.
- 후처리 : 분석이 끝나면 시스템은 추출된 텍스트 데이터를 컴퓨터 파일로 변환합니다. 일부 OCR 시스템은 문서의 스캔 버전 전과 후를 모두 포함하는 주석이 달린 PDF 파일을 생성할 수 있습니다.


# 1. Tesseract OCR

```python
import pytesseract
from PIL import Image
import re

image = Image.open(IMAGE_PATH)
text = pytesseract.image_to_string(image, lang="eng", config="--oem 1 --psm 4")
print(text)
```

## Setting
1. <code>Mac $ brew install tesseract</code>
2. <code>!pip install pytesseract</code>
3. Set option(--psm, --oem)
   - <strong>Option</strong> --psm ::
   Set Tesseract to only run a subset of layout analysis and assume
   a certain form of image. 

     - 0 = Orientation and script detection (OSD) only.
     - 1 = Automatic page segmentation with OSD. 
     - 2 = Automatic page segmentation, but no OSD, or OCR. (not implemented)
     - 3 = Fully automatic page segmentation, but no OSD. (Default)
     - 4 = Assume a single column of text of variable sizes. 
     - 5 = Assume a single uniform block of vertically aligned text. 
     - 6 = Assume a single uniform block of text. 
     - 7 = Treat the image as a single text line. 
     - 8 = Treat the image as a single word. 
     - 9 = Treat the image as a single word in a circle. 
     - 10 = Treat the image as a single character. 
     - 11 = Sparse text. Find as much text as possible in no particular order. 
     - 12 = Sparse text with OSD. 
     - 13 = Raw line. Treat the image as a single text line,
          bypassing hacks that are Tesseract-specific.
   
   - <strong>Option</strong> --oem ::
   Specify OCR Engine mode. 

     - 0 = Original Tesseract only. 
     - 1 = Neural nets LSTM only. 
     - 2 = Tesseract + LSTM. 
     - 3 = Default, based on what is available.

# 2. Easy OCR

```python
import easyocr
import cv2
from matplotlib import pyplot as plt
import numpy as np
import os
import pandas as pd

reader = easyocr.Reader(["en"])      
result = reader.readtext(IMAGE_PATH)
text = [result[res][1] for res in range(len(result))]
print(text)
```

## Setting
<code>!pip install easyocr</code><br>
<code>!pip install opencv-python</code>

# 3. MS Azure OCR API

```python
from azure.cognitiveservices.vision.computervision import ComputerVisionClient
from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes
from msrest.authentication import CognitiveServicesCredentials
import time

subscription_key = "API_key"
endpoint = "Endpoint"

computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))

local_image = open(IMAGE_PATH, "rb")

read_response = computervision_client.read_in_stream(local_image, raw=True)
read_operation_location = read_response.headers["Operation-Location"]
operation_id = read_operation_location.split("/")[-1]

while True:
    read_result = computervision_client.get_read_result(operation_id)
    if read_result.status not in ["notStarted", "running"]:
        break
    time.sleep(1)

text_results = []
if read_result.status == OperationStatusCodes.succeeded:
    text_results = [line.text for text_result in read_result.analyze_result.read_results for line in
                    text_result.lines]
print(text_results)
```

## Setting
1. [MS Azure](https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/ComputerVision)
| Computer Vision API 생성
2. <code>!pip install azure.cognitiveservices.vision.computervision</code>
